{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunuje model: Naiwny Bayes\n",
      "{'model__alpha': 0.1, 'model__fit_prior': False}:\n",
      " mean: 0.9705, std: 0.0023,\n",
      " fit_time: 0.1209, score_time: 0.0683\n",
      "\n",
      "{'model__alpha': 0.1, 'model__fit_prior': True}:\n",
      " mean: 0.9836, std: 0.0011,\n",
      " fit_time: 0.1081, score_time: 0.0561\n",
      "\n",
      "{'model__alpha': 1, 'model__fit_prior': False}:\n",
      " mean: 0.9639, std: 0.0023,\n",
      " fit_time: 0.1184, score_time: 0.0501\n",
      "\n",
      "{'model__alpha': 1, 'model__fit_prior': True}:\n",
      " mean: 0.9843, std: 0.0028,\n",
      " fit_time: 0.1292, score_time: 0.0433\n",
      "\n",
      "{'model__alpha': 10, 'model__fit_prior': False}:\n",
      " mean: 0.956, std: 0.0067,\n",
      " fit_time: 0.1182, score_time: 0.0436\n",
      "\n",
      "{'model__alpha': 10, 'model__fit_prior': True}:\n",
      " mean: 0.9786, std: 0.0041,\n",
      " fit_time: 0.1139, score_time: 0.044\n",
      "\n",
      "Tunuje model: BaggingClassifier_tree\n",
      "{'model__max_features': 0.5, 'model__n_estimators': 2}:\n",
      " mean: 0.9541, std: 0.0021,\n",
      " fit_time: 0.3602, score_time: 0.046\n",
      "\n",
      "{'model__max_features': 0.5, 'model__n_estimators': 5}:\n",
      " mean: 0.9718, std: 0.004,\n",
      " fit_time: 0.7593, score_time: 0.0759\n",
      "\n",
      "{'model__max_features': 0.5, 'model__n_estimators': 100}:\n",
      " mean: 0.977, std: 0.0019,\n",
      " fit_time: 13.2552, score_time: 0.393\n",
      "\n",
      "{'model__max_features': 0.8, 'model__n_estimators': 2}:\n",
      " mean: 0.9565, std: 0.0025,\n",
      " fit_time: 0.4924, score_time: 0.0639\n",
      "\n",
      "{'model__max_features': 0.8, 'model__n_estimators': 5}:\n",
      " mean: 0.9718, std: 0.003,\n",
      " fit_time: 1.0044, score_time: 0.0744\n",
      "\n",
      "{'model__max_features': 0.8, 'model__n_estimators': 100}:\n",
      " mean: 0.9731, std: 0.0038,\n",
      " fit_time: 15.8158, score_time: 0.3643\n",
      "\n",
      "{'model__max_features': 1.0, 'model__n_estimators': 2}:\n",
      " mean: 0.9569, std: 0.0039,\n",
      " fit_time: 0.4766, score_time: 0.0609\n",
      "\n",
      "{'model__max_features': 1.0, 'model__n_estimators': 5}:\n",
      " mean: 0.9657, std: 0.0013,\n",
      " fit_time: 0.8993, score_time: 0.0733\n",
      "\n",
      "{'model__max_features': 1.0, 'model__n_estimators': 100}:\n",
      " mean: 0.9689, std: 0.0063,\n",
      " fit_time: 13.9347, score_time: 0.2416\n",
      "\n",
      "Tunuje model: BaggingClassifier_bayes\n",
      "{'model__max_features': 0.5, 'model__n_estimators': 2}:\n",
      " mean: 0.9755, std: 0.0022,\n",
      " fit_time: 0.1712, score_time: 0.0485\n",
      "\n",
      "{'model__max_features': 0.5, 'model__n_estimators': 5}:\n",
      " mean: 0.9808, std: 0.0022,\n",
      " fit_time: 0.1384, score_time: 0.0528\n",
      "\n",
      "{'model__max_features': 0.5, 'model__n_estimators': 100}:\n",
      " mean: 0.9843, std: 0.0009,\n",
      " fit_time: 0.5548, score_time: 0.2223\n",
      "\n",
      "{'model__max_features': 0.8, 'model__n_estimators': 2}:\n",
      " mean: 0.9803, std: 0.0019,\n",
      " fit_time: 0.1299, score_time: 0.0501\n",
      "\n",
      "{'model__max_features': 0.8, 'model__n_estimators': 5}:\n",
      " mean: 0.9836, std: 0.0014,\n",
      " fit_time: 0.1307, score_time: 0.0564\n",
      "\n",
      "{'model__max_features': 0.8, 'model__n_estimators': 100}:\n",
      " mean: 0.9827, std: 0.0016,\n",
      " fit_time: 0.5317, score_time: 0.2348\n",
      "\n",
      "{'model__max_features': 1.0, 'model__n_estimators': 2}:\n",
      " mean: 0.9818, std: 0.003,\n",
      " fit_time: 0.1217, score_time: 0.0485\n",
      "\n",
      "{'model__max_features': 1.0, 'model__n_estimators': 5}:\n",
      " mean: 0.9827, std: 0.0025,\n",
      " fit_time: 0.1384, score_time: 0.0493\n",
      "\n",
      "{'model__max_features': 1.0, 'model__n_estimators': 100}:\n",
      " mean: 0.9843, std: 0.0025,\n",
      " fit_time: 0.5482, score_time: 0.227\n",
      "\n",
      "Tunuje model: RandomForest\n",
      "{'model__n_estimators': 2}:\n",
      " mean: 0.9471, std: 0.0036,\n",
      " fit_time: 0.1365, score_time: 0.0521\n",
      "\n",
      "{'model__n_estimators': 5}:\n",
      " mean: 0.9676, std: 0.0059,\n",
      " fit_time: 0.207, score_time: 0.0481\n",
      "\n",
      "{'model__n_estimators': 100}:\n",
      " mean: 0.9753, std: 0.0032,\n",
      " fit_time: 1.5159, score_time: 0.1372\n",
      "\n",
      "\n",
      "\n",
      "Testuję:\n",
      "Naiwny Bayes: 0.977\n",
      "BaggingClassifier_tree: 0.974\n",
      "BaggingClassifier_bayes: 0.984\n",
      "RandomForest: 0.98\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pprint\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sms = pd.read_table('Dane/sms.tsv', header=None, names=['label', 'message'])\n",
    "sms['label'] = sms.label.map({'ham':0, 'spam': 1})\n",
    "X = sms.message\n",
    "y = sms.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000)\n",
    "\n",
    "names = np.array([\"Naiwny Bayes\", \"Drzewo decyzyjne\", \"Regresja logistyczna\", \"SVM\",\n",
    "                 \"BaggingClassifier_tree\", \"BaggingClassifier_bayes\", \"RandomForest\"])\n",
    "\n",
    "models = [[(\"model\", MultinomialNB())],\n",
    "         [(\"model\", DecisionTreeClassifier())],\n",
    "         [(\"scaler\", MaxAbsScaler()), (\"model\", LogisticRegression())],\n",
    "         [(\"scaler\", MaxAbsScaler()),(\"model\", SVC())],\n",
    "         [(\"model\", BaggingClassifier(base_estimator=DecisionTreeClassifier()))],\n",
    "         [(\"model\", BaggingClassifier(base_estimator=MultinomialNB()))],\n",
    "         [(\"model\", RandomForestClassifier())]\n",
    "         ]\n",
    "\n",
    "param_grids = [{\"model__alpha\": [0.1, 1, 10], \"model__fit_prior\": [False, True]},\n",
    "               {\"model__criterion\": [\"gini\", \"entropy\"], \"model__min_samples_split\": [2, 10, 100], \"model__max_depth\": [None, 2, 10, 100]}, \n",
    "               {\"model__penalty\": [\"l1\", \"l2\"], \"model__C\": [0.1, 1, 10]},\n",
    "              [{\"model__kernel\": [\"rbf\"], \"model__gamma\": [0.1, 1]},\n",
    "              {\"model__kernel\": [\"poly\"], \"model__degree\": [2, 3]}],\n",
    "               {\"model__n_estimators\" : [2, 5, 100], \"model__max_features\": [0.5, 0.8, 1.0]},\n",
    "               {\"model__n_estimators\" : [2, 5, 100], \"model__max_features\": [0.5, 0.8, 1.0]},\n",
    "               {\"model__n_estimators\" : [2, 5, 100]}\n",
    "              ]\n",
    "\n",
    "uses = np.array([True, False, False, False, True, True, True])\n",
    "\n",
    "if len(names) != len(models) or len(models) != len(param_grids) or len(param_grids) != len(uses):\n",
    "    print(f\"len(names): {len(names)}\")\n",
    "    print(f\"len(models): {len(models)}\")\n",
    "    print(f\"len(param_grids): {len(param_grids)}\")\n",
    "    print(f\"len(uses): {len(uses)}\")\n",
    "    raise ValueError(\"Listy nie mają tej samej długości!\")\n",
    "\n",
    "vectorizer = [(\"vectorizer\", CountVectorizer(stop_words=\"english\", max_features=3000))]\n",
    "\n",
    "best_models = []\n",
    "\n",
    "for use, name, pipe, params in zip(uses, names, models, param_grids):\n",
    "    if not use:\n",
    "        continue\n",
    "    print(f\"Tunuje model: {name}\")\n",
    "    pipeline = Pipeline(vectorizer+pipe)\n",
    "    gs = GridSearchCV(estimator=pipeline, param_grid=params, n_jobs=3)\n",
    "    gs.fit(X_train, y_train)\n",
    "    for mean, std, param, fit_time, score_time in zip(gs.cv_results_[\"mean_test_score\"],\n",
    "                                gs.cv_results_[\"std_test_score\"],\n",
    "                                gs.cv_results_[\"params\"],\n",
    "                                gs.cv_results_[\"mean_fit_time\"],\n",
    "                                gs.cv_results_[\"mean_score_time\"]):\n",
    "        print(f\"{param}:\\n mean: {np.round(mean, 4)}, std: {np.round(std,4)},\\n fit_time: {np.round(fit_time, 4)}, score_time: {np.round(score_time,4)}\\n\")\n",
    "    best_models.append(gs.best_estimator_)\n",
    "\n",
    "best_models = np.array(best_models)\n",
    "    \n",
    "print(\"\\n\\nTestuję:\")\n",
    "for name, best_model in zip(names[uses], best_models):\n",
    "    print(f\"{name}: {accuracy_score(best_model.predict(X_test), y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
